%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Wenneker Article
% LaTeX Template
% Version 2.0 (28/2/17)
%
% This template was downloaded from:
% http://www.LaTeXTemplates.com
%
% Authors:
% Vel (vel@LaTeXTemplates.com)
% Frits Wenneker
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[10pt, a4paper, twocolumn]{article} % 10pt font size (11 and 12 also possible), A4 paper (letterpaper for US letter) and two column layout (remove for one column)

\input{structure.tex} % Specifies the document structure and loads requires packages

%----------------------------------------------------------------------------------------
%	ARTICLE INFORMATION
%----------------------------------------------------------------------------------------

\title{Sollten Algorithmen im Gericht benutzt werden, um die Rückfälligkeitswahrscheinlichkeit von Angeklagten zu berechnen? } % The article title

\author{
	\authorstyle{Gruppe: 10\\ Journalist: Jonas Opitz\\ Chefredakteur: Frank Eric Mbouga} % Authors
}

% Example of a one line author/institution relationship
%\author{\newauthor{John Marston} \newinstitution{Universidad Nacional Autónoma de México, Mexico City, Mexico}}

\date{\today} % Add a date here if you would like one to appear underneath the title block, use \today for the current date, leave empty for no date

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Print the title

\thispagestyle{firstpage} % Apply the page style for the first page (no headers and footers)


\section{Einleitung}
Welche Folgen kann es für wen geben, wenn man einen Algorithmus zum Bestimmen der Rückfälligkeitswahrscheinlichkeit von Angeklagten, wie OCEAN, im Gericht einführt?

Nachdem es im vorherigen Blogeintrag darum ging, wie Algorithmen wie Northpointes OCEAN funktionieren, soll es nun um die Konsequenzen der Einführung dieser gehen.

Um diese Frage zu betrachten wird zunächst das soziale System, d.h. die betroffenen Akteure, betrachtet, in das diese Algorithmen eingefügt werden, und ob es sich hier nach Kienle und Kunau um ein sozio-technisches System handelt.
Danach wird noch ein Mal auf die Funktionsweise von OCEAN eingegangen und diskutiert, woher die in [1] beschriebenen rassistischen Tendenzen her kommen könnten.
Zuletzt wird die primäre These dieser Diskussion über ein Vestersches Wirkungsgefüge gekräftigt.

Da Algorithmen zum Bestimmen der Rückfälligkeitswahrscheinlichkeit bereits in den USA angewandt werden, und sich die meisten Studien auf die USA beziehen, wird sich dieser Blogeintrag ebenfalls auf die USA beziehen.

\section{Das interagierende soziale System}
Auf erstem Blick scheint es vier Akteure zu geben, die von Algorithmen wie OCEAN betroffen sind:
\begin{itemize}
  \item Die Privatunternehmen, die solche Algorithmen entwickeln, vermieten und somit von ihnen profitieren.
  \item Der Gesetzgeber, der gegebenenfalls den Einsatz dieser Algorithmen regulieren muss.
  \item Die Richterschaft, für die diese Algorithmen überhaupt gemacht werden, und deren Arbeit durch diese unterstützt werden soll.
  \item Die Angeklagten, für die diese Algorithmen entscheiden, ob sie vor der Gerichtsverhandlung in das Gefängnis gehen bzw. bail zahlen müssen.
\end{itemize}
Jedoch lässt sich die letzte Gruppe von Menschen, die Angeklagten, in zwei Subgruppen unterteilen: 
\begin{itemize}
  \item Die, die historisch im Gericht bevorteilt sind (d.h. weiße Amerikaner).
  \item Die, die historisch im Gericht benachteiligt sind (besonders Afro-Amerikaner).
\end{itemize}
Dass diese Unterteilung sinnvoll ist folgt aus Studien wie [4], in denen untersucht, und bestätigt [4, Kapitel 7], wurde, ob es eine Korrelation zwischen schwereren Gerichtsurteilen und der Ethnizität der/des Angeklagten gibt.

\section{Handelt es sich um ein sozio-informatisches System?}
Um ein sozio-informatisches System nach Kienle/Kanau handelt es sich hier nicht, da die dritte Bedingung, "das technische System findet Eingang in die Selbstbeschreibung des sozialen Systems" [5], nicht erfüllt ist - das Verwenden von Algorithmen wie OCEAN dient lediglich der Unterstützung von Richtern und führt zu keiner Neuheit, die in die Selbstbeschreibung des sozialen Systems einhergehen würde.

\section{Kann ein Fragebogen rassistisch sein?}


\section{Vestersches Wirkungsgefüge}


\section{Schluss}

\pagebreak
\section{Quellen}
\begin{itemize}
  \item{[1]}: 
    Julia Angwin, Jeff Larson, Surya Mattu, Lauren Kirchner (ProPublica): \textit{“Machine Bias”}, 2016\\
    https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing (abgerufen am 19.03.2019)

  \item{ [2]}: 
    Northpointe Inc.: \textit{"Practitioner’s Guide to COMPAS Core"}, 2015\\
    https://assets.documentcloud.org/documents/2840784/Practitioner-s-Guide-to-COMPAS-Core.pdf (abgerufen am 19.03.2019)

  \item  {[3]}:
    Julia Dressel, Hany Farid: \textit{"The accuracy, fairness, and limits of predicting recidivism"},
    Publiziert 2018 in \textit{Science Advances, Vol. 4, No. 1} \\ 
    https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5777393/  (abgerufen am 19.03.2019)
  \item{[4]}:
    David S. Abrams, Marianne Bertrand, Sendhil Mullainathan: \textit{"Do Judges Vary in Their Treatment of Race?"},
    Publiziert 2012 in \textit{The Journal of Legal Studies, Vol. 41, No. 2} \\
    https://www.povertyactionlab.org/sites/default/files/publications/210\%20Do\%20Judges\%20Vary\%20Sept\%202010.pdf (abgerufen am 20.03.2019)
  \item{[5]}:
    Andrea Kienle, Gabriele Kunau: "\textit{Informatik und Gesellschaft - eine sozio-technische Perspektive"}, 2014
\end{itemize}

%----------------------------------------------------------------------------------------

\end{document}
